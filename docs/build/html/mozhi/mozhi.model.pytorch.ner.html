

<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mozhi.model.pytorch.ner &mdash; Mozhi 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../_static/css/mozhi_style.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mozhi.model.tf" href="mozhi.model.tf.html" />
    <link rel="prev" title="mozhi.model.pytorch" href="mozhi.model.pytorch.html" /> 

</head>

<body>
    <header>
        <div class="container">
            <a class="site-nav-toggle hidden-lg-up"><i class="icon-menu"></i></a>
            <a class="site-title" href="../index.html">
                Mozhi
            </a>
        </div>
    </header>


<div class="breadcrumbs-outer hidden-xs-down">
    <div class="container">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="breadcrumbs">
    
      <li><a href="../index.html">Docs</a></li>
        
          <li><a href="mozhi.html">mozhi</a></li>
        
          <li><a href="mozhi.model.html">mozhi.model</a></li>
        
          <li><a href="mozhi.model.pytorch.html">mozhi.model.pytorch</a></li>
        
      <li>mozhi.model.pytorch.ner</li>
    
    
      <li class="breadcrumbs-aside">
        
            
            <a href="../_sources/mozhi/mozhi.model.pytorch.ner.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>
</div>
    </div>
</div>
    <div class="main-outer">
        <div class="container">
            <div class="row">
                <div class="col-12 col-lg-3 site-nav">
                    
<div role="search">
    <form class="search" action="../search.html" method="get">
        <div class="icon-input">
            <input type="text" name="q" placeholder="Search" />
            <span class="icon-search"></span>
        </div>
        <input type="submit" value="Go" class="d-hidden" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
    </form>
</div>
                    <div class="site-nav-tree">
                        
                            
                            
                                <ul>
<li class="toctree-l1"><a class="reference internal" href="../setup/setup.html">Developers Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../setup/dev_machine.html">Setting up Developer Machine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/dev_machine.html#installations">Installations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/dev_machine.html#folder-structure">Folder Structure</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/docker.html">Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/docker.html#setup">1. Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/docker.html#misc">2. Misc</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/kubernetes.html">Kubernetes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/kubernetes.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/minio.html">MinIO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/minio.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/minio.html#misc">Misc</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/nvidia.html">Nvidia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/prepare_data.html">Load and Prepare Demo Data for UI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/api.html">mozhi API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/api.html#setup-requirements">Setup Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/api.html#local-machine">Local Machine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/api.html#docker">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/api.html#kubernetes">Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/ui.html">mozhi UI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/ui.html#vue-reference-links">Vue Reference Links</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/ui.html#setup-requirements">Setup Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/ui.html#local-machine">Local Machine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/ui.html#docker">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/ui.html#kubernetes">Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/ocr.html">OCR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/ocr.html#docker">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/ocr.html#models">Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/hf_model_training.html">Hugging Face Transformers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/hf_model_training.html#preparing-the-model">Preparing the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/hf_model_training.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/pt_model_training.html">Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/calamari.html">Calamari</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/calamari.html#dataset">Dataset:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/calamari.html#docker-image">Docker Image</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/databases.html">Databases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/databases.html#mysql">MYSQL</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/colab.html">Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/google_drive_fuse.html">Google Drive Fuse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/postgres.html">PostgreSQL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../setup/postgres.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/postgres.html#misc">Misc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/postgres.html#psql">PSQL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/postgres.html#configuration">Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/postgres.html#create-command">Create command</a></li>
<li class="toctree-l3"><a class="reference internal" href="../setup/postgres.html#handy-queries">Handy queries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../setup/demo_on_minikube.html">Minikube</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../study_materials/study_materials.html">Mozhi Study Materials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../study_materials/dl.html">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../study_materials/dl.html#loss-functions">Loss Functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../study_materials/model_serving.html">Model Serving</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../study_materials/model_serving.html#tensorflow-model-serving">Tensorflow Model Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="../study_materials/model_serving.html#pytorch-serve">PyTorch Serve</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../study_materials/must_have_maths.html">Must Have</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../study_materials/must_have_maths.html#kl-divergence">KL Divergence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../study_materials/must_have_maths.html#cross-entorpy">Cross Entorpy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../study_materials/must_have_maths.html#residula-connection">Residula connection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../study_materials/tf.html">Tensorflow Guides</a></li>
<li class="toctree-l2"><a class="reference internal" href="../study_materials/transformers.html">Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ner/ner.html">NER - Named Entity Recognition</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../ner/ner.html#what-is-ner">What is NER?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ner/ner.html#use-cases-of-ner">Use cases of NER?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ner/ner.html#methods-to-extract-ner">Methods to extract NER</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../ner/intro.html">NER - Named Entity Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ner/datasets.html">NER Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ner/deeplearning.html">Deep Learning Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ner/papers.html">Papers Related to NER</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ner/references.html">Wild References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="mozhi.html">mozhi</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mozhi.augmenter.html">mozhi.augmenter</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.bin.html">mozhi.bin</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.config.html">mozhi.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.dataset.html">mozhi.dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mozhi.dataset.ner.html">mozhi.dataset.ner</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.db.html">mozhi.db</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.engine.html">mozhi.engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mozhi.engine.pytorch.html">mozhi.engine.pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="mozhi.engine.tf.html">mozhi.engine.tf</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.external.html">mozhi.external</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mozhi.external.experiments.html">mozhi.external.experiments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.metrics.html">mozhi.metrics</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="mozhi.model.html">mozhi.model</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="mozhi.model.pytorch.html">mozhi.model.pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="mozhi.model.tf.html">mozhi.model.tf</a></li>
<li class="toctree-l3"><a class="reference internal" href="mozhi.model.transformers.html">mozhi.model.transformers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.nlp.html">mozhi.nlp</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mozhi.nlp.embeddings.html">mozhi.nlp.embeddings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.ocr.html">mozhi.ocr</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mozhi.ocr.text_cropping.html">mozhi.ocr.text_cropping</a></li>
<li class="toctree-l3"><a class="reference internal" href="mozhi.ocr.text_detection.html">mozhi.ocr.text_detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="mozhi.ocr.text_extraction.html">mozhi.ocr.text_extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="mozhi.ocr.text_stiching.html">mozhi.ocr.text_stiching</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.pipeline.html">mozhi.pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.preprocessor.html">mozhi.preprocessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.protocol.html">mozhi.protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.serve.html">mozhi.serve</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mozhi.serve.torch.html">mozhi.serve.torch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.transformers.html">mozhi.transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="mozhi.utils.html">mozhi.utils</a></li>
</ul>
</li>
</ul>

                            
                        
                    </div>
                </div>
                <div class="col-12 col-lg-9">
                    <div class="document">
                        
                            
  <section id="module-mozhi.model.pytorch.ner">
<span id="mozhi-model-pytorch-ner"></span><h1>mozhi.model.pytorch.ner<a class="headerlink" href="#module-mozhi.model.pytorch.ner" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<span class="target" id="module-mozhi.model.pytorch.ner.bert"></span><span class="target" id="module-mozhi.model.pytorch.ner.bilstm_crf_copy"></span><dl class="py class">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">mozhi.model.pytorch.ner.bilstm_crf_copy.</span></span><span class="sig-name descname"><span class="pre">BiLSTMCRFTorch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preprocessor_data_info</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="mozhi.protocol.html#mozhi.protocol.dataprotocol.NERPreprocessorInfo" title="mozhi.protocol.dataprotocol.NERPreprocessorInfo"><span class="pre">mozhi.protocol.dataprotocol.NERPreprocessorInfo</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">char_lstm_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">char_to_ix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_word_embeds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">char_embedding_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_gpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_cap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cap_embedding_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_crf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">char_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'LSTM'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">pytorch_lightning.core.lightning.LightningModule</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.NAME">
<span class="sig-name descname"><span class="pre">NAME</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'BiLSTMCRFTorch'</span></em><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch.configure_optimizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.configure_optimizers" title="Permalink to this definition">¶</a></dt>
<dd><p>Choose what optimizers and learning-rate schedulers to use in your optimization.
Normally you’d need one. But in the case of GANs or similar you might have multiple.</p>
<dl>
<dt>Return:</dt><dd><p>Any of these 6 options.</p>
<ul class="simple">
<li><p><strong>Single optimizer</strong>.</p></li>
<li><p><strong>List or Tuple</strong> of optimizers.</p></li>
<li><p><strong>Two lists</strong> - The first list has multiple optimizers, and the second has multiple LR schedulers (or
multiple lr_dict).</p></li>
<li><p><strong>Dictionary</strong>, with an <code class="docutils literal notranslate"><span class="pre">&quot;optimizer&quot;</span></code> key, and (optionally) a <code class="docutils literal notranslate"><span class="pre">&quot;lr_scheduler&quot;</span></code>
key whose value is a single LR scheduler or lr_dict.</p></li>
<li><p><strong>Tuple of dictionaries</strong> as described above, with an optional <code class="docutils literal notranslate"><span class="pre">&quot;frequency&quot;</span></code> key.</p></li>
<li><p><strong>None</strong> - Fit will run without any optimizer.</p></li>
</ul>
</dd>
<dt>Note:</dt><dd><p>The lr_dict is a dictionary which contains the scheduler and its associated configuration.
The default configuration is shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;scheduler&#39;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="c1"># The LR scheduler instance (required)</span>
    <span class="c1"># The unit of the scheduler&#39;s step size, could also be &#39;step&#39;</span>
    <span class="s1">&#39;interval&#39;</span><span class="p">:</span> <span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
    <span class="s1">&#39;frequency&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># The frequency of the scheduler</span>
    <span class="s1">&#39;monitor&#39;</span><span class="p">:</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="c1"># Metric for `ReduceLROnPlateau` to monitor</span>
    <span class="s1">&#39;strict&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="c1"># Whether to crash the training if `monitor` is not found</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Custom name for `LearningRateMonitor` to use</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Only the <code class="docutils literal notranslate"><span class="pre">&quot;scheduler&quot;</span></code> key is required, the rest will be set to the defaults above.</p>
</dd>
<dt>Note:</dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">frequency</span></code> value specified in a dict along with the <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> key is an int corresponding
to the number of sequential batches optimized with the specific optimizer.
It should be given to none or to all of the optimizers.
There is a difference between passing multiple optimizers in a list,
and passing multiple optimizers in dictionaries with a frequency of 1:
In the former case, all optimizers will operate on the given batch in each optimization step.
In the latter, only one optimizer will operate on the given batch at every step.
This is different from the <code class="docutils literal notranslate"><span class="pre">frequency</span></code> value specified in the lr_dict mentioned below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">optimizer_one</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">optimizer_two</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="n">optimizer_one</span><span class="p">,</span> <span class="s1">&#39;frequency&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="n">optimizer_two</span><span class="p">,</span> <span class="s1">&#39;frequency&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
<p>In this example, the first optimizer will be used for the first 5 steps,
the second optimizer for the next 10 steps and that cycle will continue.
If an LR scheduler is specified for an optimizer using the <code class="docutils literal notranslate"><span class="pre">lr_scheduler</span></code> key in the above dict,
the scheduler will only be updated when its optimizer is being used.</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># most cases</span>
<span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># multiple optimizer case (e.g.: GAN)</span>
<span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">dis_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dis</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gen_opt</span><span class="p">,</span> <span class="n">dis_opt</span>

<span class="c1"># example with learning rate schedulers</span>
<span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">dis_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dis</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">dis_sch</span> <span class="o">=</span> <span class="n">CosineAnnealing</span><span class="p">(</span><span class="n">dis_opt</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">gen_opt</span><span class="p">,</span> <span class="n">dis_opt</span><span class="p">],</span> <span class="p">[</span><span class="n">dis_sch</span><span class="p">]</span>

<span class="c1"># example with step-based learning rate schedulers</span>
<span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">dis_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dis</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">gen_sch</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;scheduler&#39;</span><span class="p">:</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">gen_opt</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span>
               <span class="s1">&#39;interval&#39;</span><span class="p">:</span> <span class="s1">&#39;step&#39;</span><span class="p">}</span>  <span class="c1"># called after each training step</span>
    <span class="n">dis_sch</span> <span class="o">=</span> <span class="n">CosineAnnealing</span><span class="p">(</span><span class="n">dis_opt</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># called every epoch</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">gen_opt</span><span class="p">,</span> <span class="n">dis_opt</span><span class="p">],</span> <span class="p">[</span><span class="n">gen_sch</span><span class="p">,</span> <span class="n">dis_sch</span><span class="p">]</span>

<span class="c1"># example with optimizer frequencies</span>
<span class="c1"># see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1</span>
<span class="c1"># https://arxiv.org/abs/1704.00028</span>
<span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">dis_opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dis</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">n_critic</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="p">{</span><span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="n">dis_opt</span><span class="p">,</span> <span class="s1">&#39;frequency&#39;</span><span class="p">:</span> <span class="n">n_critic</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="n">gen_opt</span><span class="p">,</span> <span class="s1">&#39;frequency&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Note:</dt><dd><p>Some things to know:</p>
<ul class="simple">
<li><p>Lightning calls <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> and <code class="docutils literal notranslate"><span class="pre">.step()</span></code> on each optimizer and learning rate scheduler as needed.</p></li>
<li><p>If you use 16-bit precision (<code class="docutils literal notranslate"><span class="pre">precision=16</span></code>), Lightning will automatically handle the optimizers.</p></li>
<li><p>If you use multiple optimizers, <a class="reference internal" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.training_step" title="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> will have an additional <code class="docutils literal notranslate"><span class="pre">optimizer_idx</span></code> parameter.</p></li>
<li><p>If you use <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.LBFGS</span></code>, Lightning handles the closure function automatically for you.</p></li>
<li><p>If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer
at each training step.</p></li>
<li><p>If you need to control how often those optimizers step or override the default <code class="docutils literal notranslate"><span class="pre">.step()</span></code> schedule,
override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code> hook.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">caps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chars2_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="simple">
<dt>Args:</dt><dd><p><a href="#id1"><span class="problematic" id="id2">*</span></a>args: Whatever you decide to pass into the forward method.
<a href="#id3"><span class="problematic" id="id4">**</span></a>kwargs: Keyword arguments are also possible.</p>
</dd>
<dt>Return:</dt><dd><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.neg_log_likelihood">
<span class="sig-name descname"><span class="pre">neg_log_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">caps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chars2_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch.neg_log_likelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.neg_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch.test_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.test_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the test set.
In this step you’d normally generate examples or calculate anything of interest
such as accuracy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># the pseudocode for these calls</span>
<span class="n">test_outs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">test_batch</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">test_step</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>
    <span class="n">test_outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">test_epoch_end</span><span class="p">(</span><span class="n">test_outs</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>batch (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> | (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, …) | [<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, …]):</dt><dd><p>The output of your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. A tensor, tuple or list.</p>
</dd>
</dl>
<p>batch_idx (int): The index of this batch.
dataloader_idx (int): The index of the dataloader that produced this batch</p>
<blockquote>
<div><p>(only if multiple test dataloaders used).</p>
</div></blockquote>
</dd>
<dt>Return:</dt><dd><p>Any of.</p>
<blockquote>
<div><ul class="simple">
<li><p>Any object or value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Testing will skip to the next batch</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>

<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.test_step" title="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
</pre></div>
</div>
<dl class="simple">
<dt>Note:</dt><dd><p>If you don’t need to test you don’t need to implement this method.</p>
</dd>
<dt>Note:</dt><dd><p>When the <a class="reference internal" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.test_step" title="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch.training_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Here you compute and return the training loss and some additional metrics for e.g.
the progress bar or logger.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>batch (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> | (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, …) | [<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, …]):</dt><dd><p>The output of your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. A tensor, tuple or list.</p>
</dd>
</dl>
<p>batch_idx (int): Integer displaying index of this batch
optimizer_idx (int): When using multiple optimizers, this argument will also be present.
hiddens(<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>): Passed in if</p>
<blockquote>
<div><p><a href="#id5"><span class="problematic" id="id6">:paramref:`~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps`</span></a> &gt; 0.</p>
</div></blockquote>
</dd>
<dt>Return:</dt><dd><p>Any of.</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Training will skip to the next batch</p></li>
</ul>
</dd>
<dt>Note:</dt><dd><p>Returning <code class="docutils literal notranslate"><span class="pre">None</span></code> is currently not supported for multi-GPU or TPU, or with 16-bit precision enabled.</p>
</dd>
</dl>
<p>In this step you’d normally do the forward pass and calculate the loss for a batch.
You can also do fancier things like multiple forward passes or something model specific.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>If you define multiple optimizers, this step will be called with an additional
<code class="docutils literal notranslate"><span class="pre">optimizer_idx</span></code> parameter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Multiple optimizers (e.g.: GANs)</span>
<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">optimizer_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># do training_step with encoder</span>
    <span class="k">if</span> <span class="n">optimizer_idx</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># do training_step with decoder</span>
</pre></div>
</div>
<p>If you add truncated back propagation through time you will also get an additional
argument with the hidden states of the previous step.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Truncated back-propagation through time</span>
<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">hiddens</span><span class="p">):</span>
    <span class="c1"># hiddens are the hidden states from the previous truncated backprop step</span>
    <span class="o">...</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">hiddens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">hiddens</span><span class="p">)</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;hiddens&#39;</span><span class="p">:</span> <span class="n">hiddens</span><span class="p">}</span>
</pre></div>
</div>
<dl class="simple">
<dt>Note:</dt><dd><p>The loss value shown in the progress bar is smoothed (averaged) over the last values,
so it differs from the actual loss returned in train/validation step.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch.validation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the validation set.
In this step you’d might generate examples or calculate anything of interest like accuracy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># the pseudocode for these calls</span>
<span class="n">val_outs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">val_batch</span> <span class="ow">in</span> <span class="n">val_data</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">validation_step</span><span class="p">(</span><span class="n">val_batch</span><span class="p">)</span>
    <span class="n">val_outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">validation_epoch_end</span><span class="p">(</span><span class="n">val_outs</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>batch (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> | (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, …) | [<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, …]):</dt><dd><p>The output of your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>. A tensor, tuple or list.</p>
</dd>
</dl>
<p>batch_idx (int): The index of this batch
dataloader_idx (int): The index of the dataloader that produced this batch</p>
<blockquote>
<div><p>(only if multiple val dataloaders used)</p>
</div></blockquote>
</dd>
<dt>Return:</dt><dd><p>Any of.</p>
<blockquote>
<div><ul class="simple">
<li><p>Any object or value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Validation will skip to the next batch</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pseudocode of order</span>
<span class="n">val_outs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">val_batch</span> <span class="ow">in</span> <span class="n">val_data</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">validation_step</span><span class="p">(</span><span class="n">val_batch</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">defined</span><span class="p">(</span><span class="s1">&#39;validation_step_end&#39;</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">validation_step_end</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">val_outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">val_outs</span> <span class="o">=</span> <span class="n">validation_epoch_end</span><span class="p">(</span><span class="n">val_outs</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one val dataloader:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>

<span class="c1"># if you have multiple val dataloaders:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single validation dataset</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple val dataloaders, <a class="reference internal" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.validation_step" title="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> will have an additional argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple validation dataloaders</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
</pre></div>
</div>
<dl class="simple">
<dt>Note:</dt><dd><p>If you don’t need to validate you don’t need to implement this method.</p>
</dd>
<dt>Note:</dt><dd><p>When the <a class="reference internal" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.validation_step" title="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> is called, the model has been put in eval mode
and PyTorch gradients have been disabled. At the end of validation,
the model goes back to training mode and gradients are enabled.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.viterbi_decode">
<span class="sig-name descname"><span class="pre">viterbi_decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feats</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#BiLSTMCRFTorch.viterbi_decode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.viterbi_decode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.init_embedding">
<span class="sig-prename descclassname"><span class="pre">mozhi.model.pytorch.ner.bilstm_crf_copy.</span></span><span class="sig-name descname"><span class="pre">init_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_embedding</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#init_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.init_embedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize embedding</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.init_linear">
<span class="sig-prename descclassname"><span class="pre">mozhi.model.pytorch.ner.bilstm_crf_copy.</span></span><span class="sig-name descname"><span class="pre">init_linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_linear</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#init_linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.init_linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize linear transformation</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.init_lstm">
<span class="sig-prename descclassname"><span class="pre">mozhi.model.pytorch.ner.bilstm_crf_copy.</span></span><span class="sig-name descname"><span class="pre">init_lstm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_lstm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#init_lstm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.init_lstm" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize lstm</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mozhi.model.pytorch.ner.bilstm_crf_copy.log_sum_exp">
<span class="sig-prename descclassname"><span class="pre">mozhi.model.pytorch.ner.bilstm_crf_copy.</span></span><span class="sig-name descname"><span class="pre">log_sum_exp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smat</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mozhi/model/pytorch/ner/bilstm_crf_copy.html#log_sum_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mozhi.model.pytorch.ner.bilstm_crf_copy.log_sum_exp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>


                        
                    </div>
                </div>
            </div>
        </div>
    </div>    


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
    <script type="text/javascript" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  
    <div class="footer" role="contentinfo">
        <div class="container">
            &#169; Copyright 2021, Mozhi.
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.0.1.
        </div>
    </div>  

</body>
</html>
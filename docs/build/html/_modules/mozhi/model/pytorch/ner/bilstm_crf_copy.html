

<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mozhi.model.pytorch.ner.bilstm_crf_copy &mdash; Mozhi 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../../_static/css/theme.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/css/mozhi_style.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 

</head>

<body>
    <header>
        <div class="container">
            <a class="site-nav-toggle hidden-lg-up"><i class="icon-menu"></i></a>
            <a class="site-title" href="../../../../../index.html">
                Mozhi
            </a>
        </div>
    </header>


<div class="breadcrumbs-outer hidden-xs-down">
    <div class="container">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="breadcrumbs">
    
      <li><a href="../../../../../index.html">Docs</a></li>
        
          <li><a href="../../../../index.html">Module code</a></li>
        
      <li>mozhi.model.pytorch.ner.bilstm_crf_copy</li>
    
    
      <li class="breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
    </div>
</div>
    <div class="main-outer">
        <div class="container">
            <div class="row">
                <div class="col-12 col-lg-3 site-nav">
                    
<div role="search">
    <form class="search" action="../../../../../search.html" method="get">
        <div class="icon-input">
            <input type="text" name="q" placeholder="Search" />
            <span class="icon-search"></span>
        </div>
        <input type="submit" value="Go" class="d-hidden" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
    </form>
</div>
                    <div class="site-nav-tree">
                        
                            
                            
                                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../setup/setup.html">Developers Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/dev_machine.html">Setting up Developer Machine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/dev_machine.html#installations">Installations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/dev_machine.html#folder-structure">Folder Structure</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/docker.html">Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/docker.html#setup">1. Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/docker.html#misc">2. Misc</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/kubernetes.html">Kubernetes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/kubernetes.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/minio.html">MinIO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/minio.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/minio.html#misc">Misc</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/nvidia.html">Nvidia</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/prepare_data.html">Load and Prepare Demo Data for UI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/api.html">mozhi API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/api.html#setup-requirements">Setup Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/api.html#local-machine">Local Machine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/api.html#docker">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/api.html#kubernetes">Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/ui.html">mozhi UI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/ui.html#vue-reference-links">Vue Reference Links</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/ui.html#setup-requirements">Setup Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/ui.html#local-machine">Local Machine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/ui.html#docker">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/ui.html#kubernetes">Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/ocr.html">OCR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/ocr.html#docker">Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/ocr.html#models">Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/hf_model_training.html">Hugging Face Transformers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/hf_model_training.html#preparing-the-model">Preparing the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/hf_model_training.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/pt_model_training.html">Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/calamari.html">Calamari</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/calamari.html#dataset">Dataset:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/calamari.html#docker-image">Docker Image</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/databases.html">Databases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/databases.html#mysql">MYSQL</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/colab.html">Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/google_drive_fuse.html">Google Drive Fuse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/postgres.html">PostgreSQL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/postgres.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/postgres.html#misc">Misc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/postgres.html#psql">PSQL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/postgres.html#configuration">Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/postgres.html#create-command">Create command</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../setup/postgres.html#handy-queries">Handy queries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../setup/demo_on_minikube.html">Minikube</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../study_materials/study_materials.html">Mozhi Study Materials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../study_materials/dl.html">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../study_materials/dl.html#loss-functions">Loss Functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../study_materials/model_serving.html">Model Serving</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../study_materials/model_serving.html#tensorflow-model-serving">Tensorflow Model Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../study_materials/model_serving.html#pytorch-serve">PyTorch Serve</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../study_materials/must_have_maths.html">Must Have</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../study_materials/must_have_maths.html#kl-divergence">KL Divergence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../study_materials/must_have_maths.html#cross-entorpy">Cross Entorpy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../study_materials/must_have_maths.html#residula-connection">Residula connection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../study_materials/tf.html">Tensorflow Guides</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../study_materials/transformers.html">Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ner/ner.html">NER - Named Entity Recognition</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ner/ner.html#what-is-ner">What is NER?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ner/ner.html#use-cases-of-ner">Use cases of NER?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ner/ner.html#methods-to-extract-ner">Methods to extract NER</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ner/intro.html">NER - Named Entity Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ner/datasets.html">NER Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ner/deeplearning.html">Deep Learning Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ner/papers.html">Papers Related to NER</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ner/references.html">Wild References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../mozhi/mozhi.html">mozhi</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.augmenter.html">mozhi.augmenter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.bin.html">mozhi.bin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.config.html">mozhi.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.dataset.html">mozhi.dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.dataset.ner.html">mozhi.dataset.ner</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.db.html">mozhi.db</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.engine.html">mozhi.engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.engine.pytorch.html">mozhi.engine.pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.engine.tf.html">mozhi.engine.tf</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.external.html">mozhi.external</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.external.experiments.html">mozhi.external.experiments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.metrics.html">mozhi.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.model.html">mozhi.model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.model.pytorch.html">mozhi.model.pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.model.tf.html">mozhi.model.tf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.model.transformers.html">mozhi.model.transformers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.nlp.html">mozhi.nlp</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.nlp.embeddings.html">mozhi.nlp.embeddings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.ocr.html">mozhi.ocr</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.ocr.text_cropping.html">mozhi.ocr.text_cropping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.ocr.text_detection.html">mozhi.ocr.text_detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.ocr.text_extraction.html">mozhi.ocr.text_extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.ocr.text_stiching.html">mozhi.ocr.text_stiching</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.pipeline.html">mozhi.pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.preprocessor.html">mozhi.preprocessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.protocol.html">mozhi.protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.serve.html">mozhi.serve</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mozhi/mozhi.serve.torch.html">mozhi.serve.torch</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.transformers.html">mozhi.transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mozhi/mozhi.utils.html">mozhi.utils</a></li>
</ul>
</li>
</ul>

                            
                        
                    </div>
                </div>
                <div class="col-12 col-lg-9">
                    <div class="document">
                        
                            
  <h1>Source code for mozhi.model.pytorch.ner.bilstm_crf_copy</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="kn">from</span> <span class="nn">mozhi.protocol.dataprotocol</span> <span class="kn">import</span> <span class="n">NERPreprocessorInfo</span>
<span class="kn">from</span> <span class="nn">mozhi.utils.pretty_print</span> <span class="kn">import</span> <span class="n">print_error</span><span class="p">,</span> <span class="n">print_info</span>

<span class="n">START_TAG</span> <span class="o">=</span> <span class="s2">&quot;&lt;start&gt;&quot;</span>
<span class="n">STOP_TAG</span> <span class="o">=</span> <span class="s2">&quot;&lt;stop&gt;&quot;</span>


<span class="c1"># Compute log sum exp in a numerically stable way for the forward algorithm</span>
<div class="viewcode-block" id="log_sum_exp"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.log_sum_exp">[docs]</a><span class="k">def</span> <span class="nf">log_sum_exp</span><span class="p">(</span><span class="n">smat</span><span class="p">):</span>
    <span class="c1"># status matrix (smat): (tagset_size, tagset_size)</span>
    <span class="c1"># @return (1, tagset_size)</span>
    <span class="n">max_score</span> <span class="o">=</span> <span class="n">smat</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">smat</span> <span class="o">-</span> <span class="n">max_score</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span> <span class="o">+</span> <span class="n">max_score</span></div>

<div class="viewcode-block" id="init_embedding"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.init_embedding">[docs]</a><span class="k">def</span> <span class="nf">init_embedding</span><span class="p">(</span><span class="n">input_embedding</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize embedding</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="n">input_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">input_embedding</span><span class="p">,</span> <span class="o">-</span><span class="n">bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span></div>


<div class="viewcode-block" id="init_linear"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.init_linear">[docs]</a><span class="k">def</span> <span class="nf">init_linear</span><span class="p">(</span><span class="n">input_linear</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize linear transformation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">input_linear</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">input_linear</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span></div>

<div class="viewcode-block" id="init_lstm"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.init_lstm">[docs]</a><span class="k">def</span> <span class="nf">init_lstm</span><span class="p">(</span><span class="n">input_lstm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize lstm</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">input_lstm</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">orthogonal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span></div>

<span class="c1"># https://github.com/ZubinGou/NER-BiLSTM-CRF-PyTorch/blob/main/src/model.py</span>
<div class="viewcode-block" id="BiLSTMCRFTorch"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch">[docs]</a><span class="k">class</span> <span class="nc">BiLSTMCRFTorch</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="n">NAME</span> <span class="o">=</span> <span class="s1">&#39;BiLSTMCRFTorch&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">preprocessor_data_info</span><span class="p">:</span> <span class="n">NERPreprocessorInfo</span><span class="p">,</span>
            <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">char_lstm_dim</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
            <span class="n">char_to_ix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">pre_word_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">char_embedding_dim</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
            <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">n_cap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">cap_embedding_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">use_crf</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">char_mode</span><span class="o">=</span><span class="s2">&quot;LSTM&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BiLSTMCRFTorch</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_gpu</span> <span class="o">=</span> <span class="n">use_gpu</span>
        <span class="c1"># self.device = torch.device(&quot;cuda&quot; if self.use_gpu else &quot;cpu&quot;)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">preprocessor_data_info</span><span class="o">.</span><span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span> <span class="o">=</span> <span class="n">preprocessor_data_info</span><span class="o">.</span><span class="n">t2i</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_cap</span> <span class="o">=</span> <span class="n">n_cap</span>  <span class="c1"># Capitalization feature num</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cap_embedding_dim</span> <span class="o">=</span> <span class="n">cap_embedding_dim</span>  <span class="c1"># Capitalization feature dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_crf</span> <span class="o">=</span> <span class="n">use_crf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tagset_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">char_lstm_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">char_mode</span> <span class="o">=</span> <span class="n">char_mode</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;char_mode: </span><span class="si">%s</span><span class="s2">, out_channels: </span><span class="si">%d</span><span class="s2">, hidden_dim: </span><span class="si">%d</span><span class="s2">, &quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">char_mode</span><span class="p">,</span> <span class="n">char_lstm_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">))</span>

        <span class="c1"># if self.n_cap and self.cap_embedding_dim:</span>
        <span class="c1">#     self.cap_embeds = nn.Embedding(self.n_cap, self.cap_embedding_dim)</span>
        <span class="c1">#     torch.nn.init.xavier_uniform_(self.cap_embeds.weight)</span>

        <span class="c1"># if char_embedding_dim is not None:</span>
        <span class="c1">#     self.char_lstm_dim = char_lstm_dim</span>
        <span class="c1">#     self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)</span>
        <span class="c1">#     torch.nn.init.xavier_uniform_(self.char_embeds.weight)</span>
        <span class="c1">#     if self.char_mode == &quot;LSTM&quot;:</span>
        <span class="c1">#         self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)</span>
        <span class="c1">#         init_lstm(self.char_lstm)</span>
        <span class="c1">#     if self.char_mode == &quot;CNN&quot;:</span>
        <span class="c1">#         self.char_cnn3 = nn.Conv2d(</span>
        <span class="c1">#             in_channels=1,</span>
        <span class="c1">#             out_channels=self.out_channels,</span>
        <span class="c1">#             kernel_size=(3, char_embedding_dim),</span>
        <span class="c1">#             padding=(2, 0),</span>
        <span class="c1">#         )</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">word_embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
                                        <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>

        <span class="c1"># if pre_word_embeds is not None:</span>
        <span class="c1">#     self.pre_word_embeds = True</span>
        <span class="c1">#     self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))</span>
        <span class="c1"># else:</span>
        <span class="c1">#     self.pre_word_embeds = False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># if self.n_cap and self.cap_embedding_dim:</span>
        <span class="c1">#     if self.char_mode == &quot;LSTM&quot;:</span>
        <span class="c1">#         self.lstm = nn.LSTM(</span>
        <span class="c1">#             embedding_dim + char_lstm_dim * 2 + cap_embedding_dim,</span>
        <span class="c1">#             hidden_dim,</span>
        <span class="c1">#             bidirectional=True,</span>
        <span class="c1">#             )</span>
        <span class="c1">#     if self.char_mode == &quot;CNN&quot;:</span>
        <span class="c1">#         self.lstm = nn.LSTM(</span>
        <span class="c1">#             embedding_dim + self.out_channels + cap_embedding_dim,</span>
        <span class="c1">#             hidden_dim,</span>
        <span class="c1">#             bidirectional=True,</span>
        <span class="c1">#             )</span>
        <span class="c1"># else:</span>
        <span class="c1">#     if self.char_mode == &quot;LSTM&quot;:</span>
        <span class="c1">#         self.lstm = nn.LSTM(embedding_dim + char_lstm_dim * 2, hidden_dim, bidirectional=True)</span>
        <span class="c1">#     if self.char_mode == &quot;CNN&quot;:</span>
        <span class="c1">#         self.lstm = nn.LSTM(embedding_dim + self.out_channels, hidden_dim, bidirectional=True)</span>

        <span class="c1"># self.lstm = nn.LSTM(embedding_dim + char_lstm_dim * 2, hidden_dim, bidirectional=True)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
                            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">init_lstm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">)</span>

        <span class="c1"># # high way</span>
        <span class="c1"># self.hw_trans = nn.Linear(self.out_channels, self.out_channels)</span>
        <span class="c1"># self.hw_gate = nn.Linear(self.out_channels, self.out_channels)</span>
        <span class="c1"># self.h2_h1 = nn.Linear(hidden_dim * 2, hidden_dim)</span>
        <span class="c1"># self.tanh = nn.Tanh()</span>
        <span class="c1"># init_linear(self.h2_h1)</span>
        <span class="c1"># init_linear(self.hw_gate)</span>
        <span class="c1"># init_linear(self.hw_trans)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden2tag</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tagset_size</span><span class="p">)</span>
        <span class="n">init_linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden2tag</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_crf</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tagset_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tagset_size</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">START_TAG</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10000</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">STOP_TAG</span><span class="p">],</span> <span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10000</span>

    <span class="k">def</span> <span class="nf">_score_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feats</span><span class="p">,</span> <span class="n">tags</span><span class="p">):</span>
        <span class="c1"># Gives the score of a provided tag sequence</span>
        <span class="c1"># tags is ground_truth, a list of ints, length is len(sentence)</span>
        <span class="c1"># feats is a 2D tensor, len(sentence) * tagset_size</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">feats</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pad_start_tags</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">START_TAG</span><span class="p">]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">tags</span><span class="p">])</span>
        <span class="n">pad_stop_tags</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tags</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">STOP_TAG</span><span class="p">]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)])</span>

        <span class="n">score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">[</span><span class="n">pad_start_tags</span><span class="p">,</span> <span class="n">pad_stop_tags</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">feats</span><span class="p">[</span><span class="n">r</span><span class="p">,</span> <span class="n">tags</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">score</span>

    <span class="k">def</span> <span class="nf">_get_lstm_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">chars</span><span class="p">,</span> <span class="n">caps</span><span class="p">,</span> <span class="n">chars2_length</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>

        <span class="c1"># if self.char_mode == &quot;LSTM&quot;:</span>
        <span class="c1">#     # self.char_lstm_hidden = self.init_lstm_hidden(dim=self.char_lstm_dim, bidirection=True, batchsize=chars.size(0))</span>
        <span class="c1">#     chars_embeds = self.char_embeds(chars).transpose(0, 1)</span>
        <span class="c1">#     packed = torch.nn.utils.rnn.pack_padded_sequence(chars_embeds, chars2_length)</span>
        <span class="c1">#     lstm_out, _ = self.char_lstm(packed)</span>
        <span class="c1">#     outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)</span>
        <span class="c1">#     outputs = outputs.transpose(0, 1)</span>
        <span class="c1">#     chars_embeds_temp = Variable(torch.FloatTensor(torch.zeros(</span>
        <span class="c1">#         (outputs.size(0), outputs.size(2))))).to(self.device)</span>
        <span class="c1">#     for i, index in enumerate(output_lengths):</span>
        <span class="c1">#         chars_embeds_temp[i] = torch.cat((</span>
        <span class="c1">#             outputs[i, index - 1, :self.char_lstm_dim],</span>
        <span class="c1">#             outputs[i, 0, self.char_lstm_dim:],</span>
        <span class="c1">#         ))</span>
        <span class="c1">#     chars_embeds = chars_embeds_temp.clone()</span>
        <span class="c1">#     for i in range(chars_embeds.size(0)):</span>
        <span class="c1">#         chars_embeds[d[i]] = chars_embeds_temp[i]</span>
        <span class="c1">#</span>
        <span class="c1"># if self.char_mode == &quot;CNN&quot;:</span>
        <span class="c1">#     chars_embeds = self.char_embeds(chars).unsqueeze(1)</span>
        <span class="c1">#     chars_cnn_out3 = self.char_cnn3(chars_embeds)</span>
        <span class="c1">#     chars_embeds = nn.functional.max_pool2d(chars_cnn_out3,</span>
        <span class="c1">#                                             kernel_size=(chars_cnn_out3.size(2),</span>
        <span class="c1">#                                                          1)).view(chars_cnn_out3.size(0), self.out_channels)</span>

        <span class="c1"># t = self.hw_gate(chars_embeds) # high way</span>
        <span class="c1"># g = nn.functional.sigmoid(t)</span>
        <span class="c1"># h = nn.functional.relu(self.hw_trans(chars_embeds))</span>
        <span class="c1"># chars_embeds = g * h + (1 - g) * chars_embeds</span>

        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_embeds</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>  <span class="c1"># BS X MAX_LEN x EMB</span>
        <span class="c1"># if self.n_cap and self.cap_embedding_dim:</span>
        <span class="c1">#     cap_embedding = self.cap_embeds(caps)</span>
        <span class="c1">#     embeds = torch.cat((embeds, chars_embeds, cap_embedding), 1)</span>
        <span class="c1"># else:</span>
        <span class="c1">#     embeds = torch.cat((embeds, chars_embeds), 1)</span>

        <span class="c1"># embeds = embeds.unsqueeze(1)</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">embeds</span><span class="p">)</span>
        <span class="c1"># print_error(embeds.shape)</span>
        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">embeds</span><span class="p">)</span>  <span class="c1"># BS X MAX_LEN x EMB * 2</span>
        <span class="c1"># print_error(lstm_out.shape)</span>
        <span class="c1"># lstm_out = lstm_out.view(len(sentence), self.hidden_dim * 2)</span>
        <span class="n">lstm_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>  <span class="c1"># BS X MAX_LEN x EMB * 2</span>
        <span class="c1"># print_error(lstm_out.shape)</span>
        <span class="n">lstm_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden2tag</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>  <span class="c1"># BS X MAX_LEN x NUM_TAGS</span>
        <span class="n">print_error</span><span class="p">(</span><span class="n">lstm_feats</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lstm_feats</span>

    <span class="k">def</span> <span class="nf">_forward_alg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feats</span><span class="p">):</span>
        <span class="c1"># calculate in log domain</span>
        <span class="c1"># feats is len(sentence) * tagset_size</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tagset_size</span><span class="p">),</span> <span class="o">-</span><span class="mf">10000.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">START_TAG</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feats</span><span class="p">:</span>
            <span class="n">print_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">print_info</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">log_sum_exp</span><span class="p">(</span><span class="n">alpha</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">feat</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_sum_exp</span><span class="p">(</span><span class="n">alpha</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="mi">0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">[:,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">STOP_TAG</span><span class="p">]]])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<div class="viewcode-block" id="BiLSTMCRFTorch.viterbi_decode"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.viterbi_decode">[docs]</a>    <span class="k">def</span> <span class="nf">viterbi_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feats</span><span class="p">):</span>
        <span class="n">backtrace</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tagset_size</span><span class="p">),</span> <span class="o">-</span><span class="mf">10000.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">START_TAG</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">feats</span><span class="p">:</span>
            <span class="n">smat</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">feat</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">)</span>  <span class="c1"># (tagset_size, tagset_size)</span>
            <span class="n">backtrace</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smat</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># column_max</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">log_sum_exp</span><span class="p">(</span><span class="n">smat</span><span class="p">)</span>
        <span class="c1"># backtrack</span>
        <span class="n">smat</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="mi">0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">transitions</span><span class="p">[:,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_to_ix</span><span class="p">[</span><span class="n">STOP_TAG</span><span class="p">]]]</span>
        <span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">smat</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">best_path</span> <span class="o">=</span> <span class="p">[</span><span class="n">best_tag_id</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">bptrs_t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">backtrace</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>  <span class="c1"># ignore START_TAG</span>
            <span class="n">best_tag_id</span> <span class="o">=</span> <span class="n">bptrs_t</span><span class="p">[</span><span class="n">best_tag_id</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">best_path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_tag_id</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_sum_exp</span><span class="p">(</span><span class="n">smat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">best_path</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># item() return list?</span></div>

<div class="viewcode-block" id="BiLSTMCRFTorch.neg_log_likelihood"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.neg_log_likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">neg_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">tags</span><span class="p">,</span> <span class="n">chars</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">caps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">chars2_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># sentence, tags is a list of ints</span>
        <span class="c1"># features is a 2D tensor, len(sentence) * self.tagset_size</span>
        <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lstm_features</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">chars</span><span class="p">,</span> <span class="n">caps</span><span class="p">,</span> <span class="n">chars2_length</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_crf</span><span class="p">:</span>
            <span class="n">forward_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_alg</span><span class="p">(</span><span class="n">feats</span><span class="p">)</span>
            <span class="n">gold_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_score_sentence</span><span class="p">(</span><span class="n">feats</span><span class="p">,</span> <span class="n">tags</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">forward_score</span> <span class="o">-</span> <span class="n">gold_score</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tags</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">feats</span><span class="p">,</span> <span class="n">tags</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">scores</span></div>

<div class="viewcode-block" id="BiLSTMCRFTorch.forward"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">chars</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">caps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">chars2_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lstm_features</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">chars</span><span class="p">,</span> <span class="n">caps</span><span class="p">,</span> <span class="n">chars2_length</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="c1"># viterbi to get tag_seq</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_crf</span><span class="p">:</span>
            <span class="n">score</span><span class="p">,</span> <span class="n">tag_seq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">viterbi_decode</span><span class="p">(</span><span class="n">feats</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">score</span><span class="p">,</span> <span class="n">tag_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">feats</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">tag_seq</span> <span class="o">=</span> <span class="n">tag_seq</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">tag_seq</span></div>

<div class="viewcode-block" id="BiLSTMCRFTorch.training_step"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.training_step">[docs]</a>    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>  <span class="c1"># x: [BS x MAX_LEN] , y : [BS x MAX_LEN x NUM_TAGS]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neg_log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># BS x MAX_LEN x NUM_TAGS</span>
        <span class="k">return</span> <span class="n">loss</span></div>

<div class="viewcode-block" id="BiLSTMCRFTorch.validation_step"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.validation_step">[docs]</a>    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">EvalResult</span><span class="p">()</span>
        <span class="n">result</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;val_f1&#39;</span><span class="p">,</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">),</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="BiLSTMCRFTorch.test_step"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.test_step">[docs]</a>    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;test_f1&#39;</span><span class="p">:</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)}</span></div>

<div class="viewcode-block" id="BiLSTMCRFTorch.configure_optimizers"><a class="viewcode-back" href="../../../../../mozhi/mozhi.model.pytorch.ner.html#mozhi.model.pytorch.ner.bilstm_crf_copy.BiLSTMCRFTorch.configure_optimizers">[docs]</a>    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span></div></div>
</pre></div>

                        
                    </div>
                </div>
            </div>
        </div>
    </div>    


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../../',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
    <script type="text/javascript" src="../../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>
  
    <div class="footer" role="contentinfo">
        <div class="container">
            &#169; Copyright 2021, Mozhi.
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.0.1.
        </div>
    </div>  

</body>
</html>
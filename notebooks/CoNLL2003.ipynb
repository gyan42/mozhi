{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "configured-probability",
   "metadata": {},
   "source": [
    "# CoNLL 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accredited-upgrade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.5.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from future.utils import iteritems\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pretty-opera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "natural-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "\n",
    "\n",
    "class CRF(L.Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 **kwargs):\n",
    "        \"\"\"    \n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim) \n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = L.InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'supports_masking': self.supports_masking,\n",
    "            'transitions': K.eval(self.transitions)\n",
    "        }\n",
    "        base_config = super(CRF, self).get_config()\n",
    "        return dict(base_config, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "north-passing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata  test.txt  train.txt  valid.txt\n"
     ]
    }
   ],
   "source": [
    "! ls ../data/ner/conll/2003/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subjective-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoNLLSentenceDataLoader(object):\n",
    "    def __init__(self, \n",
    "                 train_file_path, \n",
    "                 val_file_path, \n",
    "                 test_file_path,\n",
    "                 unknown_word = 'unk',\n",
    "                 text_col=0,\n",
    "                 ner_tag_col=3):\n",
    "        \n",
    "        self._text_col = text_col\n",
    "        self._ner_tag_col = ner_tag_col\n",
    "        self._unknown_word = unknown_word\n",
    "        self._train_df = self._read_txt(train_file_path)\n",
    "        self._test_df = self._read_txt(test_file_path)\n",
    "        self._val_df = self._read_txt(val_file_path)\n",
    "        \n",
    "        self.train_sentences = self._get_sentences(self._train_df)\n",
    "        self.test_sentences = self._get_sentences(self._test_df)\n",
    "        self.val_sentences = self._get_sentences(self._val_df)\n",
    "        \n",
    "        # Collect word and tag bags based on trian data\n",
    "        self.words = self._get_words(self.train_sentences)\n",
    "        self.ner_tags = self._get_tags(self.train_sentences)\n",
    "        self.max_length = self._get_max_length(self.train_sentences)\n",
    "        \n",
    "    def _read_txt(self, file_path):\n",
    "        df = pd.read_csv(file_path, \n",
    "                           sep=' ', \n",
    "                           skip_blank_lines=False, \n",
    "                           header=None).fillna(self._unknown_word)\n",
    "        # Filter out the DOCSTART lines\n",
    "        df = df[~df[0].str.contains(\"DOCSTART\")]\n",
    "        return df\n",
    "    \n",
    "    def _get_sentences(self, df):\n",
    "        current_rows = []\n",
    "        # list of list of tuples\n",
    "        sentences = []\n",
    "        \n",
    "        for i in tqdm(range(len(df))):\n",
    "            row = df.values[i]\n",
    "            if row[0] != self._unknown_word:\n",
    "                current_rows.append(row)\n",
    "            else:\n",
    "                if len(current_rows) > 2:\n",
    "                    _temp_df = pd.DataFrame(current_rows)\n",
    "                    sentences.append(list(zip(_temp_df[self._text_col].values, _temp_df[self._ner_tag_col].values)))\n",
    "                    current_rows = []\n",
    "        return sentences    \n",
    "    \n",
    "    def _get_words(self, sentences):\n",
    "        words = set()\n",
    "        for s in sentences:\n",
    "            [words.add(t[0]) for t in s]\n",
    "        return list(words)\n",
    "    \n",
    "    def _get_tags(self, sentences):\n",
    "        tags = set()\n",
    "        for s in sentences:\n",
    "            [tags.add(t[1]) for t in s]\n",
    "        return list(tags)\n",
    "    \n",
    "    def _get_max_length(self, sentences):\n",
    "        return max([len(s) for s in sentences])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reserved-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencePreprocessor(object):\n",
    "    def __init__(self, words, tags, maxlen):\n",
    "        self._words = words\n",
    "        self._tags = tags\n",
    "        \n",
    "        self.n_words = len(words)\n",
    "        self.n_tags = len(tags)\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "        self._word2idx = {w: i for i, w in enumerate(self._words)}\n",
    "        self._tag2idx = {t: i for i, t in enumerate(self._tags)}\n",
    "        self._idx2tag = {v: k for k, v in iteritems(self._tag2idx)}\n",
    "        \n",
    "    def sentences_2_data(self, sentences):\n",
    "        X = [[self._word2idx.get(w[0], self.n_words - 1) for w in s] for s in sentences]\n",
    "        X = tf.keras.preprocessing.sequence.pad_sequences(maxlen=self.maxlen, sequences=X, padding=\"post\", value=self.n_words - 1)\n",
    "\n",
    "        y = [[self._tag2idx.get(w[1], 'unk') for w in s] for s in sentences]\n",
    "        y = tf.keras.preprocessing.sequence.pad_sequences(maxlen=self.maxlen, sequences=y, padding=\"post\", value=self._tag2idx[\"O\"])\n",
    "        y = [tf.keras.utils.to_categorical(i, num_classes=self.n_tags) for i in y]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fitted-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMCRF(object):\n",
    "    def __init__(self,\n",
    "                 num_words,\n",
    "                 num_tags,\n",
    "                 sentence_max_length,\n",
    "                 word_embeddings_size=64,\n",
    "                 checkpoint_dir=os.path.join(str(Path.home()), '.mozhi')):\n",
    "        self._word_embeddings_size = word_embeddings_size\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._filepath = \"vf-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "        inputs = Input(shape=(sentence_max_length,))\n",
    "\n",
    "        # Embedding Layer\n",
    "        model = tf.keras.layers.Embedding(input_dim=num_words,\n",
    "                                          output_dim=word_embeddings_size,\n",
    "                                          input_length=sentence_max_length)(inputs)\n",
    "\n",
    "        # BI-LSTM Layer\n",
    "        model = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=word_embeddings_size,\n",
    "                                                                   return_sequences=True,\n",
    "                                                                   dropout=0.5,\n",
    "                                                                   recurrent_dropout=0.5,\n",
    "                                                                   kernel_initializer=tf.keras.initializers.HeNormal()))(model)\n",
    "\n",
    "        model = tf.keras.layers.LSTM(units=word_embeddings_size * 2,\n",
    "                                     return_sequences=True,\n",
    "                                     dropout=0.5,\n",
    "                                     recurrent_dropout=0.5,\n",
    "                                     kernel_initializer=tf.keras.initializers.HeNormal())(model)\n",
    "\n",
    "        # TimeDistributed Layer\n",
    "        model = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_tags,\n",
    "                                                                      activation=\"relu\"))(model)\n",
    "\n",
    "        self._crf = CRF(num_tags, sparse_target=True)\n",
    "        outputs = self._crf(model)  # output\n",
    "\n",
    "        self.model = Model(inputs, outputs)\n",
    "        self.model.summary()\n",
    "\n",
    "    def _get_optimizer(self):\n",
    "        return tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer=self._get_optimizer(),\n",
    "                           loss=self._crf.loss,\n",
    "                           metrics=[self._crf.accuracy, 'accuracy'])\n",
    "\n",
    "    def fit(self,\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=256,\n",
    "            epochs=20,\n",
    "            validation_split=0.1,\n",
    "            verbose=1):\n",
    "        # Saving the best model only\n",
    "        checkpoint = ModelCheckpoint(self._checkpoint_dir + \"/\" + self._filepath,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     verbose=1,\n",
    "                                     save_best_only=True,\n",
    "                                     mode='max')\n",
    "        callbacks_list = [checkpoint]\n",
    "\n",
    "        # Fit the best model\n",
    "        history = self.model.fit(X,\n",
    "                                 np.array(y),\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 validation_split=validation_split,\n",
    "                                 verbose=verbose,\n",
    "                                 callbacks=callbacks_list)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "special-rider",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218608/218608 [00:08<00:00, 26154.97it/s]\n",
      "100%|██████████| 50119/50119 [00:02<00:00, 23705.52it/s]\n",
      "100%|██████████| 54828/54828 [00:01<00:00, 28146.74it/s]\n"
     ]
    }
   ],
   "source": [
    "conll_loader = CoNLLSentenceDataLoader(train_file_path=\"../data/ner/conll/2003/train.txt\", \n",
    "                                      val_file_path=\"../data/ner/conll/2003/valid.txt\", \n",
    "                                      test_file_path=\"../data/ner/conll/2003/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "exotic-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SentencePreprocessor(conll_loader.words, conll_loader.ner_tags, conll_loader.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minute-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = preprocessor.sentences_2_data(conll_loader.train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "uniform-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 113)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 113, 64)           1511808   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 113, 128)          66048     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 113, 128)          131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 113, 10)           1290      \n",
      "_________________________________________________________________\n",
      "crf_2 (CRF)                  (None, 113, 10)           100       \n",
      "=================================================================\n",
      "Total params: 1,710,830\n",
      "Trainable params: 1,710,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMCRF(num_words=preprocessor.n_words,\n",
    "                 num_tags=preprocessor.n_tags,\n",
    "                 sentence_max_length=conll_loader.max_length,\n",
    "                 word_embeddings_size=64)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "boring-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "46/46 [==============================] - 35s 583ms/step - loss: 61.7802 - viterbi_accuracy: 0.8815 - accuracy: 0.9484 - val_loss: 168.1039 - val_viterbi_accuracy: 0.9779 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97644, saving model to /home/mageswarand/.mozhi/vf-bi-lstm-td-model-0.98.hdf5\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 34s 750ms/step - loss: 16.1078 - viterbi_accuracy: 0.9750 - accuracy: 0.9749 - val_loss: 168.0284 - val_viterbi_accuracy: 0.9779 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.97644\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 30s 655ms/step - loss: 14.2255 - viterbi_accuracy: 0.9750 - accuracy: 0.9749 - val_loss: 167.9112 - val_viterbi_accuracy: 0.9779 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.97644\n",
      "Epoch 4/20\n",
      "10/46 [=====>........................] - ETA: 21s - loss: 13.5601 - viterbi_accuracy: 0.9752 - accuracy: 0.9752"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-9588e40aeb38>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m         verbose=1)\n\u001B[0m",
      "\u001B[0;32m<ipython-input-19-4bb989ea8b9e>\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, batch_size, epochs, validation_split, verbose)\u001B[0m\n\u001B[1;32m     71\u001B[0m                                  \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidation_split\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m                                  \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m                                  callbacks=callbacks_list)\n\u001B[0m\u001B[1;32m     74\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhistory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1181\u001B[0m                 _r=1):\n\u001B[1;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1183\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1184\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    915\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 917\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    918\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   3023\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 3024\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1960\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1961\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1963\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    594\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m/opt/envs/ai4e/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X=trainX,\n",
    "        y=trainY,\n",
    "        batch_size=256,\n",
    "        epochs=20,\n",
    "        validation_split=0.1,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(accuracy) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
    "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = preprocessor.sentences_2_data(conll_loader.test_sentences)\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(preprocessor._idx2tag[p_i])\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "test_pred = model.predict(testX, verbose=1)   \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-health",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
